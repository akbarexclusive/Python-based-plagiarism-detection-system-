from flask import Flask, request, jsonify
from flask_cors import CORS
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

app = Flask(__name__)
CORS(app)

# Download required NLTK data
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('punkt')
    nltk.download('stopwords')

def preprocess_text(text):
    """Preprocess the text by converting to lowercase and removing stopwords."""
    try:
        words = text.lower().split()
        stop_words = set(stopwords.words('english'))
        return ' '.join([word for word in words if word not in stop_words])
    except Exception as e:
        print(f"Error in preprocessing: {str(e)}")
        return text

def check_plagiarism(answer, corpus):
    """Check for plagiarism using cosine similarity."""
    try:
        vectorizer = TfidfVectorizer()
        vectors = vectorizer.fit_transform([answer] + corpus)
        similarity_scores = cosine_similarity(vectors[0:1], vectors[1:])[0]
        max_similarity = float(max(similarity_scores) * 100) if len(similarity_scores) > 0 else 0.0
        return bool(max_similarity < 30)  # Explicitly convert to bool
    except Exception as e:
        print(f"Error in plagiarism check: {str(e)}")
        return True

def calculate_english_quality(text):
    """Calculate English quality score."""
    try:
        words = text.lower().split()
        if not words:
            return 0.0
        return float(len(set(words)) / len(words))
    except Exception as e:
        print(f"Error in English quality calculation: {str(e)}")
        return 0.0

@app.route('/evaluate', methods=['POST'])
def evaluate_answer():
    """Evaluate the submitted answer."""
    try:
        data = request.json
        if not data or 'answer' not in data:
            return jsonify({
                'error': 'No answer provided'
            }), 400

        answer = data.get('answer', '')
        
        # Preprocess the answer
        preprocessed_answer = preprocess_text(answer)
        
        # Sample corpus (replace with your actual corpus)
        corpus = ["sample answer 1", "sample answer 2"]
        
        # Perform evaluations
        is_original = check_plagiarism(preprocessed_answer, corpus)
        english_quality = calculate_english_quality(answer)
        accuracy = 0.75  # Example fixed score
        
        # Construct response with explicit type conversion
        response = {
            'is_original': bool(is_original),
            'english_quality': float(english_quality),
            'accuracy': float(accuracy)
        }
        
        return jsonify(response)

    except Exception as e:
        print(f"Error in evaluate_answer: {str(e)}")
        return jsonify({
            'error': str(e),
            'message': 'An error occurred while evaluating the answer'
        }), 500

if __name__ == '__main__':
    app.run(debug=True)
